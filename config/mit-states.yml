model:
  model_name: EGLGE 
  prompt_template: ["a photo of x x", "a photo of x", "a photo of x"]
  ctx_init: ["a photo of ", "a photo of ", "a photo of "]
  clip_model: "ViT-L/14"
  adapter_dim: 64
  adapter_dropout: 0.1
  pair_loss_weight: 1.0
  pair_inference_weight: 1.0
  attr_loss_weight: 1.0
  attr_inference_weight: 1.0
  obj_loss_weight: 1.0
  obj_inference_weight: 1.0
  graph_loss_weight: 1.0
  graph_inference_weight: 1.0
  graph_attr_loss_weight: 0.01
  graph_attr_inference_weight: 0.01
  graph_obj_loss_weight: 0.001
  graph_obj_inference_weight: 0.001
  l1_loss_weight: 0.00001
  exclusive_loss_weight: 0.1

train:
  dataset: mit-states
  # dataset_path:
  optimizer: Adam #SGD #Adam
  scheduler: StepLR
  step_size: 5
  gamma: 0.5
  lr: 0.0001
  attr_dropout: 0.3
  weight_decay: 0.00001
  context_length: 8
  train_batch_size: 64
  gradient_accumulation_steps: 1
  # seed:
  epochs: 10
  epoch_start: 0
  # save_path:
  val_metric: AUC # best_loss
  save_final_model: True
  # load_model: False     # False or model path
  graph_gr_emb: d4096,d
  graph_emb_dim: 768
  graph_gcn_type: gcn # graphsage # gcn
  beta: 0.001
  lr_adj: 0.01
  train_mask_step: 5
  lambda_l1: 0.01 # L1 正则化系数
  lambda_exclusive: 0.1 # Exclusive Group Lasso 正则化系数
  save_every_n: 50


test:
  eval_batch_size: 128
  open_world: False # False
  # load_model:
  topk: 1
  text_encoder_batch_size: 1024
  # threshold: 0.4
  threshold_trials: 50
  bias: 0.001
  text_first: True

